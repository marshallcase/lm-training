{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b5f91f2",
   "metadata": {},
   "source": [
    "# play around with a trained model from outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a20a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Import our local modules\n",
    "import sys\n",
    "sys.path.append(\".\")  # Add the root directory to path\n",
    "from lmtraining.config import Config, ModelConfig\n",
    "from lmtraining.models.transformer import TransformerModel\n",
    "from lmtraining.data.dataset import create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dd8634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76123d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "def load_model_from_checkpoint(checkpoint_dir):\n",
    "    \"\"\"Load a trained model from checkpoint directory.\"\"\"\n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        raise FileNotFoundError(f\"Checkpoint directory not found: {checkpoint_dir}\")\n",
    "    \n",
    "    # Load configuration\n",
    "    config_path = os.path.join(checkpoint_dir, \"config.json\")\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "    \n",
    "    model_config = ModelConfig.from_json(config_path)\n",
    "    \n",
    "    # Load training arguments if available\n",
    "    training_args_path = os.path.join(checkpoint_dir, \"training_args.json\")\n",
    "    if os.path.exists(training_args_path):\n",
    "        with open(training_args_path, 'r') as f:\n",
    "            training_args = json.load(f)\n",
    "        print(f\"Loaded training arguments: {training_args}\")\n",
    "    \n",
    "    # Create model instance\n",
    "    model = TransformerModel(model_config)\n",
    "    \n",
    "    # Load model weights\n",
    "    weights_path = os.path.join(checkpoint_dir, \"pytorch_model.bin\")\n",
    "    if not os.path.exists(weights_path):\n",
    "        raise FileNotFoundError(f\"Model weights file not found: {weights_path}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    return model, model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d65556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training logs to analyze training progress\n",
    "def load_and_parse_logs(output_dir):\n",
    "    \"\"\"Parse training logs to extract loss values over time.\"\"\"\n",
    "    # Find all log files in the output directory\n",
    "    checkpoint_dirs = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))\n",
    "    \n",
    "    # Sort checkpoints by step number\n",
    "    checkpoint_dirs.sort(key=lambda x: int(x.split(\"-\")[-1]))\n",
    "    \n",
    "    # Collect training data\n",
    "    training_data = []\n",
    "    \n",
    "    # Process each checkpoint\n",
    "    for checkpoint_dir in checkpoint_dirs:\n",
    "        step = int(checkpoint_dir.split(\"-\")[-1])\n",
    "        \n",
    "        # Look for optimizer state which contains the global step\n",
    "        optimizer_path = os.path.join(checkpoint_dir, \"optimizer.pt\")\n",
    "        if os.path.exists(optimizer_path):\n",
    "            optimizer_data = torch.load(optimizer_path, map_location=\"cpu\")\n",
    "            if \"best_metric\" in optimizer_data:\n",
    "                best_metric = optimizer_data[\"best_metric\"]\n",
    "                perplexity = math.exp(best_metric) if best_metric < 20 else float('inf')\n",
    "                training_data.append({\n",
    "                    \"step\": step,\n",
    "                    \"loss\": best_metric,\n",
    "                    \"perplexity\": perplexity\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if training_data:\n",
    "        return pd.DataFrame(training_data)\n",
    "    else:\n",
    "        print(\"No training logs found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47571059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model on text\n",
    "def evaluate_perplexity(model, tokenizer, text, context_length=512):\n",
    "    \"\"\"Evaluate model perplexity on the given text.\"\"\"\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \n",
    "    # Process in overlapping chunks if the text is long\n",
    "    stride = context_length // 2\n",
    "    nlls = []\n",
    "    \n",
    "    # Process the text in chunks \n",
    "    for i in range(0, len(tokens) - stride, stride):\n",
    "        chunk = tokens[i:i + context_length]\n",
    "        input_ids = torch.tensor([chunk]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "            \n",
    "        # Get loss\n",
    "        if isinstance(outputs, dict):\n",
    "            neg_log_likelihood = outputs[\"loss\"].item() * len(chunk)\n",
    "        else:\n",
    "            neg_log_likelihood = outputs[0].item() * len(chunk)\n",
    "            \n",
    "        nlls.append(neg_log_likelihood)\n",
    "    \n",
    "    if not nlls:\n",
    "        return float('inf')\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    avg_nll = sum(nlls) / len(tokens)\n",
    "    perplexity = math.exp(avg_nll)\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cdce428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text from the model\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0, top_k=50, top_p=0.95):\n",
    "    \"\"\"Generate text using the trained model.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Initialize generation parameters\n",
    "    generated = input_ids\n",
    "    \n",
    "    # Generate text\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            outputs = model(input_ids=generated)\n",
    "            \n",
    "            if isinstance(outputs, dict):\n",
    "                next_token_logits = outputs[\"logits\"][:, -1, :] / temperature\n",
    "            else:\n",
    "                next_token_logits = outputs[0][:, -1, :] / temperature\n",
    "            \n",
    "            # Apply top-k filtering\n",
    "            if top_k > 0:\n",
    "                indices_to_remove = next_token_logits < torch.topk(next_token_logits, top_k)[0][..., -1, None]\n",
    "                next_token_logits[indices_to_remove] = -float('Inf')\n",
    "            \n",
    "            # Apply top-p (nucleus) filtering\n",
    "            if top_p < 1.0:\n",
    "                sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
    "                cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "                \n",
    "                # Remove tokens with cumulative probability above the threshold\n",
    "                sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                # Shift the indices to the right to keep the first token above threshold\n",
    "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "                sorted_indices_to_remove[..., 0] = 0\n",
    "                \n",
    "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "                next_token_logits[0, indices_to_remove] = -float('Inf')\n",
    "            \n",
    "            # Sample from the filtered distribution\n",
    "            probs = torch.softmax(next_token_logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # Add the token to the generated sequence\n",
    "            generated = torch.cat((generated, next_token), dim=1)\n",
    "            \n",
    "            # Stop if we generate an EOS token\n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "    \n",
    "    # Decode the generated tokens\n",
    "    generated_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d153ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "def plot_training_progress(df):\n",
    "    \"\"\"Plot training loss and perplexity over time.\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"No data to plot.\")\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    # Plot loss\n",
    "    sns.lineplot(x=\"step\", y=\"loss\", data=df, ax=ax1)\n",
    "    ax1.set_title(\"Training Loss Over Time\")\n",
    "    ax1.set_xlabel(\"Training Step\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot perplexity\n",
    "    sns.lineplot(x=\"step\", y=\"perplexity\", data=df, ax=ax2)\n",
    "    ax2.set_title(\"Perplexity Over Time\")\n",
    "    ax2.set_xlabel(\"Training Step\")\n",
    "    ax2.set_ylabel(\"Perplexity\")\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8fcea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/marshall/lmodel/outputs/lm-wikitext/best_model...\n",
      "Loaded training arguments: {'output_dir': 'outputs/lm-wikitext', 'seed': 42, 'train_batch_size': 8, 'eval_batch_size': 8, 'gradient_accumulation_steps': 4, 'learning_rate': 5e-05, 'weight_decay': 0.01, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'warmup_steps': 0, 'warmup_ratio': 0.1, 'logging_steps': 100, 'save_steps': 1000, 'save_total_limit': 3, 'evaluation_strategy': 'steps', 'eval_steps': 500, 'use_amp': True}\n",
      "Model loaded: 256 hidden size, 6 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97370/4051623056.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model_path = \"/home/marshall/lmodel/outputs/lm-wikitext/best_model\"\n",
    "logs_dir = \"outputs/lm-wikitext\"  # This should be the parent directory of all checkpoints\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer_name = \"gpt2\"  # Update this to match what you used during training\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load model\n",
    "print(f\"Loading model from {model_path}...\")\n",
    "model, model_config = load_model_from_checkpoint(model_path)\n",
    "print(f\"Model loaded: {model_config.hidden_size} hidden size, {model_config.num_hidden_layers} layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9aa2e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training logs from outputs/lm-wikitext...\n",
      "No training logs found.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading training logs from {logs_dir}...\")\n",
    "training_df = load_and_parse_logs(logs_dir)\n",
    "if training_df is not None:\n",
    "    print(\"Training data loaded. Here are the first few rows:\")\n",
    "    print(training_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
